\subsection{L'implémentation de la méthode de spatialisation}

Pour permettre la confrontation de notre méthode à la réalité, nous
avons développé un prototype, baptisé \emph{Ruitor} \footnote{Le nom
  Ruitor fut porté par un Saint-Bernard célèbre du
  \bsc{xix}\up{ème}.}, implémentant l'ensemble de la méthode que nous
avons développée, c'est-à-dire les phases de décomposition, de
spatialisation et de fusion. Par ailleurs, l'ensemble des résultats
que nous avons présentés jusqu'ici (à l'exceptions de ceux présentés
dans le \autoref{chap:06}) et ceux qui seront présentés dans ce
chapitre, ont été réalisés avec ce prototype.

\emph{Ruitor} a été entièrement développé à l'aide du langage de
programmation python, dans sa version 3.5, de septembre 2015
\autocite{VanRossum2009}. Ce langage a été sélectionné pour deux
raisons principales :
%
\begin{enumerate*}[label=(\arabic*)]
\item D'une part, car c'est un langage de programmation avec lequel
  nous avons une certaine expérience \autocite{Bunel2017b,Bunel2017c},
  ce qui nous a permis de limiter le temps de développement consacré à
  la résolution de problèmes qui auraient pu être causés par une
  mauvaise maitrise du langage.
\item D'autre part, il s'agit d'un langage populaire et répandu,
  notamment en géomatique, que ce soit dans la recherche ou dans le
  milieu professionnel. De nombreuses bibliothèques utiles pour
  l'implémentation de notre méthode sont donc développées dans ce
  langage.
\end{enumerate*}
%
Le choix d'un langage de développement ne fixe pas à lui seul le cadre
d'un développement. En effet, plusieurs approches de développement,
utilisant le même langage, sont envisageables. Une première solution
serait d'employer le \emph{cadriciel} fourni par les différents SIG
professionnels, comme QGis ou ArcGis. Cette solution permet de
disposer des nombreuses fonctions de manipulation, d'analyse et de
visualisation de ces logiciels. Cette approche a cependant deux
défauts, dont l'un majeur. Tout d'abord, il est nécessaire de se
familiariser avec ces fonctions spécifiques, ce qui peut nécessiter un
temps d’apprentissage conséquent, bien que cette remarque soit valable
pour n'importe quelle bibliothèque logicielle. De plus, le choix
d'utiliser le \emph{cadriciel} d'un SIG donné, impose une forte
dépendance à ce logiciel, ce qui peut considérablement augmenter la
difficulté du déploiement d'un logiciel fondé sur ces technologies. À
la réflexion, l'utilisation du \emph{cadriciel} d'un SIG nous semble
plus adapté à un développement de \emph{scripts} ---~de petits
logiciels conçus pour une tâche spécifique et déclenchés manuellement
par l'utilisateur~---, étendant les fonctionnalités d'un SIG, plutôt
que d'un logiciel unique, fonctionnant de manière quasi-automatisée.

Le rejet des \emph{cadriciels} d'un SIG n'impose, cependant, pas de se
passer de toute bibliothèque de manipulations de données
géométriques. Certains projets libres, au premier rang desquels on
trouve les développements de \emph{l'open géo consortium} (OGC),
proposent de nombreuses bibliothèques permettant la manipulation de
données géographiques, qu'elles soient représentées par des vecteurs
ou des rasters. Cependant, les fonctions qui auraient été regroupées
dans un même \emph{cadriciel,} sont alors dispersées entre plusieurs
bibliothèques indépendantes, généralement plus flexibles, mais qui ne
sont pas nécessairement conçues pour fonctionner ensemble.

Choisir entre un \emph{cadriciel} de SIG et un ensemble de
bibliothèques indépendantes, revient donc à choisir entre un cadre de
développement cohérent, mais contraignant par son apprentissage et sa
mise en place, et un ensemble de bibliothèques indépendantes, plus
versatiles. Nous avons privilégié la seconde option, les contraintes
apportées par les \emph{cadriciels} de SIG étant trop restrictives.

Les trois phases de notre méthode traitant d'objets différents (\ie
des \emph{indices de localisation} dans la phase de décomposition et
des \ac{zlc} dans la phase de spatialisation et de fusion), il nous
est nécessaire d'employer des bibliothèques spécifiques pour chacune
des tâches, ce qui a compliqué le processus de développement.

% Implémentation de la phase de décomposition

Lors de la présentation de la \emph{phase de décomposition}
(\autoref{chap:05}), nous avions indiqué que la difficulté la mise en
place de cette phase était concentrée sur la dernière étape : la
décomposition des \emph{relations de localisation,} les \emph{indices
  de localisation} et les \emph{objets de référence} étant déjà
décomposés lors de leur saisie par le secouriste. Par corolaire,
l'implémentation des deux premières étapes de la phase de
décomposition ne pose pas, non plus, de problèmes particuliers.

En effet, au début de la phase de décomposition ---~et donc de la
méthode dans son ensemble~--- nous disposons de la requête du
secouriste formalisée dans une structure de données que nous avons
nous-même définie. Les \emph{différents indices de localisation} sont
regroupés dans \emph{l'ensemble des indices de localisation} et, si
les \emph{indices de localisations} se réfèrent à plusieurs
\emph{objets de référence} (\ie dans le cas où les objets de référence
ne sont pas nommés) alors ces derniers sont explicitement présents
dans la requête. Ainsi, la requête transmise par le secouriste
contient l'ensemble des informations nécessaires à la décomposition de
l'ensemble des \emph{indices de localisation} et à la décomposition
des objets de référence non nommés. Du point de vue de
l'implémentation, ces deux étapes se résument en la transformation
d'une structure de données (la requête du secouriste) en une autre,
que l'on sait traiter. La troisième étape de la phase de
décomposition, la \emph{décomposition des relations de localisation,}
a nécessité un travail d'implémentation plus important. Comme nous
l'avons indiqué dans le \autoref{chap:05}, la décomposition des
relations de localisation nécessite des informations supplémentaires à
celles transmises par le secouriste. Ces informations sont explicitéés
dans \emph{l'ontologie des relations de localisation} \acp{orl}. La
réalisation de cette dernière étape de la phase de localisation
nécessite donc de lire et d'interpréter les informations formalisées
dans l'ontologie \ac{orl}. Dans Ruitor, cette tâche est principalement
effectuée à l'aide de la bibliothèque \emph{Owlready}
\autocite{Lamy2017}, permettant la lecture et la manipulation
d'ontologies OWL. Cette bibliothèque nous permet de lire les
informations présentes dans \ac{orl} et \ac{orla} afin d'identifier
les relations de localisation atomiques décomposant, le cas échéant,
les relations de localisation utilisées par le secouriste et
d'identifier le \emph{rasteriser,} la \emph{métrique} et le
\emph{fuzzyficateur} utilisés pour spatialiser les relations de
localisation atomiques.

% Implémentation des phases de spatialisation \& de fusion
Les phases de spatialisation et de fusion sont implémentées de manière
très différente de la phase de décomposition. En effet, ces phases
nécessitent la manipulation et le traitement d'objets géographiques,
contrairement à la phase de décomposition. La mise en place de ces
étapes nécessite donc de mettre en place de nouveaux outils pour
manipuler les géométries. Notre travail faisant une grande utilisation
de rasters, la bibliothèque permettant leur manipulation prend une
place centrale lors de cette étape. Dans l'état actuel de
l'implémentation, nous ne pouvons traiter que des objets de référence
représentés sous la forme de données vectorielles. Ces données sont
traitées à l'aide des bibliothèques python \emph{fiona}
\autocite{Gillies2020a}, \emph{shapely} \autocite{Gillies2020} et
\emph{gdal} \autocite{GDAL2020}, qui nous permettent de manipuler et
de rasteriser les objets vectoriels. La première étape de la
spatialisation, la rasterisation (\autoref{chap:07}), est donc
effectuée à l'aide de ces trois bibliothèques.

La manipulation des rasters, au cœur de notre travail, est construite
autour de la bibliothèque \emph{numpy,} conçue pour le calcul
scientifique et plus précisément la manipulation optimisée de matrices
volumineuses \autocite{vanderWalt2011}. Le type de données, défini par
\emph{numpy} \footnote{Le \emph{ndarray,} pour
  \foreigntextquote{english}{N-dimensional array} (Tableau
  multidimensionnel).}, fait office de standard du calcul scientifique
dans l'univers \emph{python,} il est donc à la base de nombreuses
bibliothèques de calcul scientifique. Cette bibliothèque est complétée
par la bibliothèque \emph{rasterio} \autocite{Mapbox2020} qui permet
de traiter des rasters comme des matrices \emph{numpy.} Les étapes de
\emph{calcul de la métrique} et de \emph{fuzzyfication} sont
effectuées directement avec \emph{numpy.} La bibliothèque \emph{numpy}
permet d'effectuer de nombreux calculs avancés, ce qui nous permet de
calculer de nombreux types de \emph{métriques.} Toutefois, certaines
méthodes spécifiques, qui pourraient être utiles pour le calcul de
certaines \emph{métriques,} n'y figurent pas. C'est pourquoi nous
avons également fait appel aux bibliothèques \emph{SciPy} et
\emph{scikit-image} \autocite{vanderWalt2014,Virtanen2020} qui
proposent des outils supplémentaires, utiles pour le calcul de
certaines métriques (\eg distance à la partie la plus proche de
l'objet de référence), tout en opérant de à partir des types de
données définis par \emph{numpy.}

Les \emph{zones de localisation} \emph{compatibles} et
\emph{probables} sont directement représentées par des matrices
\emph{numpy.} Nous avons cependant développé une bibliothèque, basée
sur \emph{rasterio} \autocite{Mapbox2020}, permettant de simplifier et
d'automatiser au maximum la création de rasters flous (et donc, dans
le cas présent la phase de fuzzyfication) et les opérations
inter-raster, comme les unions et les intersections.

Dans son état actuel, Ruitor n'offre pas encore la possibilité de
traiter directement les indices saisis dans l'interface développée au
sein du projet Choucas \autocite{Viry2019a} et de lui renvoyer les
\emph{zones de localisation compatibles} et \emph{probables}
construites. La mise en commun de ces deux travaux de développement
nécessite de travailler à la définition d'une interface commune. Bien
que cette mise en commune ne soit pas un objectif de cette thèse, mais
plutôt un objectif a moyen-terme du projet Choucas, ce travail a été
entamé et est toujours en cours à l'heure actuelle. L'objectif premier
étant de proposer un prototype intégré et fonctionnel au \ac{pghm}
d'ici la fin du projet Choucas.

\subsection{Présentation des alertes}

Nous ne pouvions, dans le cadre de ce travail et de ce manuscrit,
traiter l'ensemble des alertes dont nous disposons. Nous avons donc
choisi de nous focaliser sur deux d'entre elles, présentant des
caractéristiques pertinentes à étudier et permettant d'aborder des
problèmes différents.

La première des alertes que nous avons sélectionnée est l’alerte dite
du \emph{Grand Veymont.} Il s'agit d'une alerte relativement courte et
contenant moins d'une vingtaine d'indices de localisations. Bien
qu'elle soit courte, des indices de localisation de nombreux types
différents y sont présents et des relations de localisation assez
différentes sont énoncées. Cette alerte est relativement simple à
traiter. En effet, tous les \emph{objets de référence} utilisés par le
requérant pour décrire sa position sont nommés et les descriptions
données sont assez précises. Toutefois, des relations de localisation
assez variées sont utilisées. La modélisation de cette alerte nous
permet donc d'aborder de nombreuses questions de modélisation, tout en
évitant les problèmes liés à la modélisation d'indices de localisation
imprécis.

La seconde alerte traitée est le \emph{fil rouge.} Le nombre d'indices
de localisation qu'elle contient est relativement similaire, mais là
où les indices de la première alerte sont relativement précis, ceux du
\emph{fil rouge} sont très imprécis, comme nous l'avons déjà
mentionné. Cette seconde alerte est donc beaucoup plus difficile à
modéliser. Le traitement de ces deux alertes nous permet donc de
traiter de nombreuses questions de modélisation. Toutes deux emploient
des relations de localisation différentes et posent des question
inédites. À elles seules, ces deux alertes ne permettent cependant pas
de modéliser toutes les relations de localisation que nous avons
définies dans l'ontologie \ac{orl}. Cependant, elles permettent d'en
traiter un grand nombre et donc de donner un regard assez complet sur
l'exercice de la spatialisation d'alertes réelles.

Il est à noter que le processus de modélisation des alertes que nous
présentons ici est quelque peu différent de celui qui sera mis en
place lors de l'utilisation réelle de notre solution. En effet, on
s'attend à ce que lors d'une utilisation normale de Ruitor (par le
biais de l'interface développée dans le lot 2), le secouriste saisit
les indices de localisation en direct, à partir des informations que
le requérant lui donne par téléphone. Ainsi, si certaines informations
ne sont pas suffisantes pour utiliser une relation de localisation
donnée (\eg une estimation de temps de marche, sans préciser la
vitesse de temps de marche ou une indication d'orientation sans
préciser le référentiel), le secouriste peut demander des précisions
et compléter ou modifier des indices qu'il aurait saisi autrement (ou
pas pris en compte) sans plus d'informations. Il est donc envisageable
que dans une utilisation \enquote{normale} de notre prototype, les
secouristes tendent à se focaliser sur un nombre réduit
\emph{d'indices de localisation,} en cherchant à les exploiter au
maximum.

Les traitements que nous proposons ici sont quelque peu différents. En
effet, nous proposons de construire les \emph{zones de localisation
  probables} correspondant à des alertes déjà traitées. Ainsi, nous ne
pouvons reproduire la démarche qu'auraient les secouristes lors d'une
utilisation \enquote{normale} de notre prototype. Nous ne pouvons que
chercher à identifier les indices de localisation correspondant aux
informations données durant la conversation entre le secouriste et le
requérant. Ainsi, là où l'utilisation que nous envisageons pour Ruitor
nécessite une démarche active, nous ne pouvons avoir qu'une démarche
passive. Les exemples que nous proposons ici ne doivent donc pas être
interprétés comme une illustration fiable, voire un manuel, du
processus à suivre pour spatialiser les descriptions de position
données par le requérant, mais plutôt comme une discussion autour de
la modélisation d'une partie des relations de localisation et sur les
problèmes qu'elles peuvent soulever.

\subsection{Données}

La spatialisation des alertes sélectionnées nécessite la définition
d'une base de données géographique contenant l'ensemble des objets
géographiques pouvant faire office \emph{d'objets de référence.} La
mise en place de cette base de données n'est nécessaire que pour le
test de notre implémentation, l'objectif final du projet étant que
notre solution de spatialisation s'appuie sur une base de données et
un référentiel métier dont l’élaboration et la mise en place est
effectuée au sein d'un autre axe du projet Choucas (\autoref{chap:02}
et \cite{VanDamme2019}).

Pour définir cette base de données, nous avons employé les données
produites par l'IGN, qui présentent l'avantage d'offrir une couverture
de précision et de qualité constante sur l'ensemble de l'aire étudiée
(contrairement à des données saisies bénévolement comme
\emph{OpenStreetMap,} pour lesquelles la qualité et la complétude des
données saisies ne dépendent que des contributeurs). L'ensemble des
\emph{objets de référence} utilisés pour la spatialisation des indices
de localisation proviennent de la même base de données, la BD TOPO
\autocite{IGN2020}. Pour nos modélisations, nous avons travaillé
exclusivement à partir de la version de 2018. Une base de données
comme la BDTOPO a le contenu approximatif d'une carte topographique,
dont elle est la source de données principale. Ainsi, certains objets
présents sur le territoire et susceptibles d'être utilisés comme
objets de référence par des requérants peuvent ne pas y figurer.

Les données vectorielles utilisées pour la représentation des
\emph{objets de référence} donnés ne sont pas les seules dont nous
ayons besoin pour traiter les alertes. Il est en effet nécessaire de
disposer de données altimétriques, sous la forme de \ac{mnt}, pour
spatialiser des \emph{indices de localisation} impactés par le relief,
comme le temps de marche (\onto[orl]{A\-Temps\-De\-Marche}), les
relations traitant de verticalité (\eg \onto[orl]{Sous\-Altitude}), ou
la visibilité (\onto[orl]{Site\-Voit\-Cible}). Pour disposer de
données altimétriques, nous avons utilisé la BD ALTI
\autocite{IGN2020a} (dans sa version de 2018), qui est la composante
altimétrique du référentiel à grande échelle de l'IGN.

L'ensemble des indices de localisation modélisés ci-dessous le sont
donc à partir de ces deux bases de données, la BD TOPO et la BD Alti
de 2018.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../../../main"
%%% End:
