L’application de notre méthode à des alertes réelles nécessite la mise
en place  

Il est tout d'abord nécessaire de procéder à l'implémentation de la
méthode que nous avons définie.

Puis il est nécessaire de sélectionner les alertes à modéliser

Enfin, il convient de définir les données utilisées lors de la
spatialisation.

\subsection{L'implémentation de la méthode de spatialisation}

Pour permettre la confrontation de notre méthode à la réalité, nous
avons développé un prototype, baptisé \emph{Ruitor} \footnote{Le nom
  Ruitor fut porté par un Saint-Bernard célèbre du
  \bsc{xix}\up{ème}.}, implémentant l'ensemble de la méthode que nous
avons développée, c'est-à-dire les phases de décomposition, de
spatialisation et de fusion. Par ailleurs, l'ensemble des résultats
que nous avons présentées jusqu'ici (à l'exceptions de celles
présentes dans le \autoref{chap:06}) et celles qui seront présentées
dans ce chapitre, ont été réalisées avec ce prototype.

\emph{Ruitor} a été entièrement développé à l'aide du langage de
programmation python, dans sa version 3.5, de septembre 2015
\autocite{VanRossum2009}. Ce langage a été sélectionné pour deux
raisons principales :
%
\begin{enumerate*}[label=(\arabic*)]
\item D'une part, car c'est un langage de programmation avec lequel
  nous avons une certaine expérience \autocite{Bunel2017b,Bunel2017c},
  ce qui nous a permis de limiter le temps de développement consacré à
  la résolution de problèmes qui auraient pu être causés par une
  mauvaise maitrise du langage.
\item De plus, il s'agit d'un langage populaire et répandu, notamment
  en géomatique, que ce soit dans la recherche ou dans le milieu
  professionnel. De nombreuses bibliothèques utiles pour
  l'implémentation de notre méthode sont donc développées dans ce
  langage.
\end{enumerate*}
%
Le choix d'un langage de développement ne fixe pas à lui seul le cadre
d'un développement. En effet, plusieurs approches de développement,
utilisant le même langage, sont envisageables. Une première solution
serait d'employer le \emph{cadriciel} fourni par les différents SIG
professionnels, comme QGis ou ArcGis. Cette solution permet de
disposer des nombreuses fonctions de manipulation, d'analyse et de
visualisation de ces logiciels. Cette approche a cependant deux
défauts, dont l'un majeur. Tout d'abord il est nécessaire de se
familiariser avec ces fonctions spécifiques, ce qui peut nécessiter un
temps d’apprentissage conséquent, bien que cette remarque soit valable
pour n'importe quelle bibliothèque logicielle. De plus, le choix
d'utiliser le \emph{cadriciel} d'un SIG donné, impose une forte
dépendance à ce logiciel, ce qui peut considérablement augmenter la
difficulté du déploiement d'un logiciel fondé sur ces technologies. À
la réflexion, l'utilisation du \emph{cadriciel} d'un SIG nous semble
plus adapté à un développement de \emph{scripts} ---~de petits
logiciels conçus pour une tâche spécifique et déclenchés manuellement
par l'utilisateur~---, étendant les fonctionnalités d'un SIG, plutôt
que d'un logiciel unique, fonctionnant de manière quasi-automatisée.

Le rejet des \emph{cadriciels} d'un SIG n'impose, cependant, pas de se
passer de toute bibliothèque de manipulations de données
géométriques. Certains projets libres, au premier rang desquels on
trouve les développements de \emph{l'open géo consortium} (OGC),
proposent de nombreuses bibliothèques permettant la manipulation de
données géographiques, qu'elles soient représentées par des vecteurs
ou des rasters. Cependant, les fonctions qui auraient été regroupées
dans un même \emph{cadriciel,} sont alors dispersées entre plusieurs
bibliothèques indépendantes, généralement plus flexibles, mais qui ne
sont pas nécessairement conçues pour fonctionner ensemble.

Choisir entre un \emph{cadriciel} de SIG et un ensemble de
bibliothèques indépendantes, revient donc à choisir entre un cadre de
développement cohérent, mais contraignant par son apprentissage et sa
mise en place, et un ensemble de bibliothèques indépendantes, plus
versatiles. Nous avons privilégié la seconde option, les contraintes
apportées par les \emph{cadriciels} de SIG étant trop restrictives.

Les trois phases de notre méthode traitant d'objets différents (\ie
des \emph{indices de localisation} dans la phase de décomposition et
des \ac{zlc} dans la phase de spatialisation et de fusion), il nous
est nécessaire d'employer des bibliothèques spécifiques pour chacune
des tâches, ce qui a compliqué le processus de développement.

% Implémentation de la phase de décomposition

Lors de la présentation de la \emph{phase de décomposition}
(\autoref{chap:05}), nous avions indiqué que la difficulté de sa mise
en place de cette était concentrée sur la dernière étape : la
décomposition des \emph{relations de localisation,} les \emph{indices
  de localisation} et les \emph{objets de référence} étant déjà
décomposés lors de leur saisie par le secouriste. Par corolaire,
l'implémentation des deux premières étapes de la phase de
décomposition ne pose pas, non plus, de problèmes particuliers.

En effet, au début de la phase de décomposition ---~et donc de la
méthode dans son ensemble~--- nous disposons de la requête du
secouriste formalisée dans une structure de données que nous avons
nous-même définie. Les \emph{différents indices de localisation} sont
regroupés dans \emph{l'ensemble des indices de localisation} et, si
les \emph{indices de localisations} se référent à plusieurs
\emph{objets de référence} (\ie dans le cas où les objets de référence
ne sont pas nommés) alors ces derniers sont explicitement présents
dans la requête. Ainsi, la requête transmise par le secouriste
contient l'ensemble des informations nécessaires à la décomposition de
l'ensemble des \emph{indices de localisation} et à la décomposition
des objets de référence non nommés. Du point de vue de
l'implémentation ces deux étapes se résument en la transformation
d'une structure de données (la requête du secouriste) en une autre,
que l'on sait traiter. La troisième étape de la phase de
décomposition, la \emph{décomposition des relations de localisation,}
a nécessité un travail d'implémentation plus important. Comme nous
l'avons indiqué dans le \autoref{chap:05} la décomposition des
relations de localisation nécessite des informations supplémentaires à
celles transmises par le secouriste. Ces informations sont explicités
dans \emph{l'ontologie des relation de localisation} \acp{orl}. La
réalisation de cette dernière étape de la phase de localisation
nécessite donc lire et d'interpréter les informations formalisées dans
l'ontologie \ac{orl}. Dans Ruitor, cette tâche est principalement
effectuée à l'aide de la bibliothèque \emph{Owlready}
\autocite{Lamy2017}, permettant la lecture et la manipulation
d'ontologies OWL. Cette bibliothèque nous permet de lire les
informations présentes dans \ac{orl} et \ac{orla} afin d'identifier
les relations de localisation atomiques décomposant, le cas échéant,
les relations de localisation utilisées par le secouriste et
d'identifier le \emph{rasteriser,} la \emph{métrique} et le
\emph{fuzzyficateur} utilisés pour spatialiser les relations de
localisation atomiques. 

% Implémentation des phases de spatialisation \& de fusion
Les phases de spatialisation et de fusion sont implémentées de manière
très différente de la phase de décomposition. En effet, ces phases
nécessitent la manipulation et le traitement d'objets géographiques,
contrairement à phase de décomposition. La mise en place de ces étapes
nécessite donc de mettre en place de nouveaux outils pour manipuler
les géométries. Notre travail faisant une grande utilisation de
rasters, la bibliothèque permettant leur manipulation prend une place
centrale lors de cette étape. Dans l'état actuel de l'implémentation,
nous ne pouvons traiter que des objets de référence représentés sous
la forme de données vectorielles. Ces données sont traitées à l'aide
des bibliothèques python \emph{fiona} \autocite{Gillies2020a},
\emph{shapely} \autocite{Gillies2020} et \emph{gdal}
\autocite{GDAL2020}, qui nous permettent de manipuler et de rasteriser
les objets vectoriels. La première étape de la spatialisation, la
rasterisation (\autoref{chap:07}) est donc effectuée à l'aide de ces
trois bibliothèques.

La manipulation des rasters, au cœur de notre travail, est construite
autour de la bibliothèque \emph{numpy,} conçue pour le calcul
scientifique et plus précisément la manipulation optimisée de matrices
volumineuses \autocite{vanderWalt2011}. Le type de données défini par
\emph{numpy} \footnote{Le \emph{ndarray,} pour
  \foreigntextquote{english}{N-dimensional array} (Tableau
  multidimensionnel).} fait office de standard du calcul scientifique
dans l'univers du python, il est donc à la base de nombreuses
bibliothèques de calcul scientifique. Cette bibliothèque est complétée
par la bibliothèque \emph{rasterio} \autocite{Mapbox2020} qui permet
de traiter des rasters comme des matrices \emph{numpy.} Les étapes de
\emph{calcul de la métrique} et de \emph{fuzzyfication} sont
effectuées directement avec \emph{numpy.}

La bibliothèque \emph{numpy}
permet d'effectuer de nombreux calculs avancés, toutefois certaines
méthodes spécifiques n'y figurent pas, c'est pourquoi nous avons
également fait appel aux bibliothèques \emph{SciPy} et
\emph{scikit-image} \autocite{vanderWalt2014,Virtanen2020} qui
proposent des outils supplémentaires tout en opérant de à partir des
types de données définis par \emph{numpy.}



\subsection{Présentation des alertes}

Nous ne pouvions, dans le cadre de ce travail et de ce manuscrit,
traiter l'ensemble des alertes dont nous disposons. Nous avons donc
choisi de nous focaliser sur certaines d'entre-elles, présentant 




L'ensemble des retranscriptions et des \emph{templates} de
retranscription qui y sont associés sont présentés dans
l'\autoref{anx:retrans}.


\subsubsection{Statistiques}

Pour justifier le choix des alertes nous avons fait des stats 

%Todo
% \tdi{Dire qu'il est nécessaire de faire une analyse de transcription
% priori, ce qui ne sera pas le cas lors de l’utilisation concrète de
% RUITOR car le secouriste le fera}

Citer icc



\subsection{Données}

La spatialisation des alertes sélectionnées nécessite la définition
d'une base de données géographique contenant l'ensemble des objets
géographiques pouvant faire office \emph{d'objets de référence.}

La mise en place de cette base de données n'est nécessaire que pour le
test de notre implémentation, dans la version finale les données sont
stoquées dans une base de données construite dans un autre axe du
projet CHOUCAS (\autoref{chap:02}).
 

L'ensemble des \emph{objets de référence} utilisés pour la
spatialisation des indices de localisation proviennent de la même base
de données, la BDTOPO, produite par l'IGN \autocite{IGN2020}. Cette
dernière
%
Pour nos modélisations nous avons travaillé exclusivement à partir du
millésime de 2018.


Une base de données comme la BDTOPO, ne propose pas une représentation
exhaustive et à l'échelle unitaire du territoire qu'elle
cartographie. Tous les objets du territoire n'y figurent pas et les
géométries qui les représentent ne sont que des abstractions
simplifiée de la forme réelle de l'objet.

Le principal problème d'une telle base de donnée est donc que certains
objets du réels, pouvant donc être utilisés comme \emph{objets de
  référence} dans un \emph{indice de localisation,} n'y figurent pas
nécessairement.

Les données vectorielles utilisées pour la représentation des
\emph{objets de référence données} ne sont pas les seules dont nous
ayons besoin pour traiter les alertes. Il est en effet nécessaire de
disposer d e données altimétriques, sous la forme de \ac{mnt}, pour
spatialiser des \emph{indices de localisation} impactés par le relief,
comme le temps de marche (\onto[orl]{A\-Temps\-De\-Marche}), les
relations traitant de verticalité (\eg \onto[orl]{Sous\-Altitude}), ou
la visibilité (\onto[orl]{Site\-Voit\-Cible}). Pour disposer de
données altimétriques nous avons utilisé la BDALTI, qui est la
composante altimétrique du référentiel à grande échelle de l'IGN.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../../../main"
%%% End:
